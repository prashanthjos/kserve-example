{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying Fraud Detection Model with KServe\n",
    "\n",
    "In this notebook, we'll deploy our trained fraud detection model using KServe InferenceService."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import json\n",
    "from kubernetes import client, config\n",
    "from kserve import KServeClient\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Docker Images for Custom Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the transformer image\n",
    "!docker build -f Dockerfile.transformer -t fraud-detection-transformer:latest .\n",
    "\n",
    "# Build the explainer image\n",
    "!docker build -f Dockerfile.explainer -t fraud-detection-explainer:latest ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model and Deploy with KServe\n",
    "\n",
    "Now we'll deploy the model with KServe using the InferenceService."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Kubernetes configuration\n",
    "config.load_kube_config()\n",
    "\n",
    "# Create KServe client\n",
    "kserve_client = KServeClient()\n",
    "\n",
    "# Load the InferenceService YAML\n",
    "with open('kserve/inferenceservice.yaml', 'r') as f:\n",
    "    inferenceservice = yaml.safe_load(f)\n",
    "\n",
    "# Deploy the InferenceService\n",
    "kserve_client.create(inferenceservice)\n",
    "\n",
    "print(f\"InferenceService {inferenceservice['metadata']['name']} deployed in namespace {inferenceservice['metadata']['namespace']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the service to be ready\n",
    "service_name = inferenceservice['metadata']['name']\n",
    "namespace = inferenceservice['metadata']['namespace']\n",
    "\n",
    "def wait_for_service_ready(name, namespace, timeout_minutes=5):\n",
    "    start_time = time.time()\n",
    "    timeout = timeout_minutes * 60\n",
    "    \n",
    "    while time.time() - start_time < timeout:\n",
    "        try:\n",
    "            response = kserve_client.get(name, namespace=namespace)\n",
    "            conditions = response.get('status', {}).get('conditions', [])\n",
    "            \n",
    "            # Check if the service is ready\n",
    "            for condition in conditions:\n",
    "                if condition.get('type') == 'Ready' and condition.get('status') == 'True':\n",
    "                    print(f\"Service {name} is ready!\")\n",
    "                    return True\n",
    "            \n",
    "            print(f\"Waiting for service {name} to be ready...\")\n",
    "            time.sleep(10)\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking service status: {e}\")\n",
    "            time.sleep(10)\n",
    "    \n",
    "    print(f\"Timeout waiting for service {name} to be ready\")\n",
    "    return False\n",
    "\n",
    "wait_for_service_ready(service_name, namespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Advanced KServe Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy with Transformer\n",
    "with open('kserve/transformer.yaml', 'r') as f:\n",
    "    transformer_service = yaml.safe_load(f)\n",
    "\n",
    "# Update the existing service to add transformer\n",
    "kserve_client.replace(transformer_service)\n",
    "\n",
    "print(f\"Added transformer to {service_name}\")\n",
    "wait_for_service_ready(service_name, namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy with Explainer\n",
    "with open('kserve/explainer.yaml', 'r') as f:\n",
    "    explainer_service = yaml.safe_load(f)\n",
    "\n",
    "# Update the existing service to add explainer\n",
    "kserve_client.replace(explainer_service)\n",
    "\n",
    "print(f\"Added explainer to {service_name}\")\n",
    "wait_for_service_ready(service_name, namespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Inference Service Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the URLs for the inference service\n",
    "service = kserve_client.get(service_name, namespace=namespace)\n",
    "\n",
    "# Extract service URLs\n",
    "predictor_url = None\n",
    "transformer_url = None\n",
    "explainer_url = None\n",
    "\n",
    "if 'status' in service and 'url' in service['status']:\n",
    "    base_url = service['status']['url']\n",
    "    \n",
    "    # Predictor URL\n",
    "    predictor_url = f\"{base_url}/v1/models/{service_name}:predict\"\n",
    "    \n",
    "    # Transformer URL (if exists)\n",
    "    if 'transformer' in service['spec']:\n",
    "        transformer_url = f\"{base_url}/v1/models/{service_name}:predict\"\n",
    "    \n",
    "    # Explainer URL (if exists)\n",
    "    if 'explainer' in service['spec']:\n",
    "        explainer_url = f\"{base_url}/v1/models/{service_name}:explain\"\n",
    "\n",
    "print(f\"Predictor URL: {predictor_url}\")\n",
    "print(f\"Transformer URL: {transformer_url}\")\n",
    "print(f\"Explainer URL: {explainer_url}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
